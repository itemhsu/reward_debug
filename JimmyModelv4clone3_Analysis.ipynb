
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JimmyModelv4clone3 Training Log Analysis\n",
    "\n",
    "This notebook analyzes the training logs from JimmyModelv4clone3_traininglog.tar.gz\n",
    "\n",
    "## Overview\n",
    "This appears to be a reinforcement learning training log for an autonomous driving model, likely for **AWS DeepRacer** based on the data structure and variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the training log archive (if not already extracted)\n",
    "import tarfile\n",
    "if not os.path.exists('traininglog'):\n",
    "    with tarfile.open('JimmyModelv4clone3_traininglog.tar.gz', 'r:gz') as tar:\n",
    "        tar.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure of the extracted files\n",
    "for root, dirs, files in os.walk('traininglog'):\n",
    "    level = root.replace('traininglog', '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        print(f'{subindent}{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all CSV files and their sizes\n",
    "csv_files = glob.glob('traininglog/sim-trace/training/training-simtrace/*.csv')\n",
    "csv_files = sorted(csv_files, key=lambda x: int(x.split('/')[-1].split('-')[0]))\n",
    "\n",
    "print('File\\t\\t\\tSize (lines)')\n",
    "print('-' * 40)\n",
    "for file in csv_files:\n",
    "    with open(file, 'r') as f:\n",
    "        line_count = sum(1 for line in f)\n",
    "    filename = os.path.basename(file)\n",
    "    print(f'{filename}\\t\\t{line_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the structure of the data\n",
    "sample_file = 'traininglog/sim-trace/training/training-simtrace/0-iteration.csv'\n",
    "df_sample = pd.read_csv(sample_file)\n",
    "\n",
    "print('Dataset Shape:', df_sample.shape)\n",
    "print('\\nColumn Names:')\n",
    "for i, col in enumerate(df_sample.columns):\n",
    "    print(f'{i+1:2d}. {col}')\n",
    "\n",
    "print('\\nData Types:')\n",
    "print(df_sample.dtypes)\n",
    "\n",
    "print('\\nFirst 5 rows:')\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_csv_file(filename):\n",
    "    \"\"\"Analyze a single CSV file and return statistics\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = list(reader)\n",
    "    \n",
    "    # Basic statistics\n",
    "    stats = {\n",
    "        'total_rows': len(rows),\n",
    "        'episodes': set(),\n",
    "        'max_progress': 0,\n",
    "        'rewards': [],\n",
    "        'actions': defaultdict(int),\n",
    "        'episode_statuses': defaultdict(int)\n",
    "    }\n",
    "    \n",
    "    for row in rows:\n",
    "        stats['episodes'].add(int(float(row['episode'])))\n",
    "        stats['max_progress'] = max(stats['max_progress'], float(row['progress']))\n",
    "        stats['rewards'].append(float(row['reward']))\n",
    "        stats['actions'][int(float(row['action']))] += 1\n",
    "        stats['episode_statuses'][row['episode_status']] += 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def analyze_episode(filename, episode_num):\n",
    "    \"\"\"Analyze a specific episode in detail\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        episode_data = [row for row in reader if int(float(row['episode'])) == episode_num]\n",
    "    \n",
    "    if not episode_data:\n",
    "        return None\n",
    "    \n",
    "    analysis = {\n",
    "        'episode_num': episode_num,\n",
    "        'total_steps': len(episode_data),\n",
    "        'final_status': episode_data[-1]['episode_status'],\n",
    "        'progress_achieved': float(episode_data[-1]['progress']),\n",
    "        'track_length': float(episode_data[0]['track_len']),\n",
    "        'start_position': (float(episode_data[0]['X']), float(episode_data[0]['Y'])),\n",
    "        'end_position': (float(episode_data[-1]['X']), float(episode_data[-1]['Y'])),\n",
    "        'actions': [int(float(row['action'])) for row in episode_data],\n",
    "        'rewards': [float(row['reward']) for row in episode_data]\n",
    "    }\n",
    "    \n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Training Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all iterations\n",
    "iteration_files = sorted(glob.glob('traininglog/sim-trace/training/training-simtrace/*-iteration.csv'), \n",
    "                        key=lambda x: int(x.split('/')[-1].split('-')[0]))\n",
    "\n",
    "print('=== Comprehensive Training Progress Analysis ===\\n')\n",
    "\n",
    "all_results = {}\n",
    "for filename in iteration_files:\n",
    "    iteration_num = int(filename.split('/')[-1].split('-')[0])\n",
    "    stats = analyze_csv_file(filename)\n",
    "    all_results[iteration_num] = stats\n",
    "    \n",
    "    print(f'Iteration {iteration_num}:')\n",
    "    print(f'  Episodes: {min(stats["episodes"])}-{max(stats["episodes"])} ({len(stats["episodes"])} episodes)')\n",
    "    print(f'  Steps: {stats["total_rows"]}')\n",
    "    print(f'  Max progress: {stats["max_progress"]:.1f}%')\n",
    "    print(f'  Avg reward: {sum(stats["rewards"])/len(stats["rewards"]):.3f}')\n",
    "    \n",
    "    # Count successful completions\n",
    "    lap_completes = stats['episode_statuses'].get('lap_complete', 0)\n",
    "    off_tracks = stats['episode_statuses'].get('off_track', 0)\n",
    "    print(f'  Lap completions: {lap_completes}')\n",
    "    print(f'  Off-track incidents: {off_tracks}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics\n",
    "total_episodes = sum(len(result['episodes']) for result in all_results.values())\n",
    "total_steps = sum(result['total_rows'] for result in all_results.values())\n",
    "total_completions = sum(result['episode_statuses'].get('lap_complete', 0) for result in all_results.values())\n",
    "total_off_tracks = sum(result['episode_statuses'].get('off_track', 0) for result in all_results.values())\n",
    "\n",
    "print('=== Training Summary ===')\n",
    "print(f'Total episodes across all iterations: {total_episodes}')\n",
    "print(f'Total steps: {total_steps}')\n",
    "print(f'Total lap completions: {total_completions}')\n",
    "print(f'Total off-track incidents: {total_off_tracks}')\n",
    "print(f'Overall success rate: {total_completions/total_episodes*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Success rate by iteration\n",
    "iterations = list(range(11))\n",
    "success_rates = []\n",
    "for i in iterations:\n",
    "    completions = all_results[i]['episode_statuses'].get('lap_complete', 0)\n",
    "    episodes = len(all_results[i]['episodes'])\n",
    "    success_rate = completions / episodes * 100\n",
    "    success_rates.append(success_rate)\n",
    "\n",
    "ax1.bar(iterations, success_rates, color='steelblue', alpha=0.7)\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Success Rate (%)')\n",
    "ax1.set_title('Success Rate by Iteration')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Average reward by iteration\n",
    "rewards_by_iteration = []\n",
    "for i in iterations:\n",
    "    avg_reward = sum(all_results[i]['rewards'])/len(all_results[i]['rewards'])\n",
    "    rewards_by_iteration.append(avg_reward)\n",
    "\n",
    "ax2.plot(iterations, rewards_by_iteration, marker='o', linewidth=2, markersize=6, color='green')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Average Reward')\n",
    "ax2.set_title('Average Reward by Iteration')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Steps per iteration\n",
    "steps_by_iteration = [all_results[i]['total_rows'] for i in iterations]\n",
    "ax3.bar(iterations, steps_by_iteration, color='orange', alpha=0.7)\n",
    "ax3.set_xlabel('Iteration')\n",
    "ax3.set_ylabel('Total Steps')\n",
    "ax3.set_title('Total Steps by Iteration')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Action distribution (iteration 4 - best performing)\n",
    "best_iteration = 4\n",
    "actions = all_results[best_iteration]['actions']\n",
    "action_nums = list(actions.keys())\n",
    "action_counts = list(actions.values())\n",
    "\n",
    "ax4.bar(action_nums, action_counts, color='purple', alpha=0.7)\n",
    "ax4.set_xlabel('Action ID')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title(f'Action Distribution (Iteration {best_iteration})')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Episode Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and analyze successful episodes\n",
    "print('=== Successful Episode Analysis ===\\n')\n",
    "\n",
    "# Find successful episodes from iteration 4 (best performing)\n",
    "with open('traininglog/sim-trace/training/training-simtrace/4-iteration.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    successful_episodes = []\n",
    "    for row in reader:\n",
    "        if row['episode_status'] == 'lap_complete':\n",
    "            successful_episodes.append(int(float(row['episode'])))\n",
    "\n",
    "successful_episodes = list(set(successful_episodes))\n",
    "print(f'Successful episodes in iteration 4: {successful_episodes}')\n",
    "\n",
    "if successful_episodes:\n",
    "    # Analyze the first successful episode\n",
    "    episode_analysis = analyze_episode('traininglog/sim-trace/training/training-simtrace/4-iteration.csv', \n",
    "                                     successful_episodes[0])\n",
    "    \n",
    "    print(f'\\nDetailed analysis of Episode {episode_analysis["episode_num"]}:')\n",
    "    print(f'  Total steps: {episode_analysis["total_steps"]}')\n",
    "    print(f'  Final status: {episode_analysis["final_status"]}')\n",
    "    print(f'  Progress achieved: {episode_analysis["progress_achieved"]:.1f}%')\n",
    "    print(f'  Track length: {episode_analysis["track_length"]:.2f} meters')\n",
    "    print(f'  Start position: ({episode_analysis["start_position"][0]:.2f}, {episode_analysis["start_position"][1]:.2f})')\n",
    "    print(f'  End position: ({episode_analysis["end_position"][0]:.2f}, {episode_analysis["end_position"][1]:.2f})')\n",
    "    print(f'  Action sequence (first 10): {episode_analysis["actions"][:10]}')\n",
    "    print(f'  Total reward: {sum(episode_analysis["rewards"]):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Space Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Action Space Analysis ===')\n",
    "print('Based on the action distributions, this appears to be a reinforcement learning model')\n",
    "print('training for autonomous driving/racing (likely AWS DeepRacer based on the structure).\\n')\n",
    "\n",
    "print('Action space appears to include 14 different actions (0-13)')\n",
    "print('These likely represent combinations of:')\n",
    "print('- Steering: Left, Straight, Right (possibly multiple angles)')\n",
    "print('- Throttle: Different speed levels\\n')\n",
    "\n",
    "# Analyze action usage across all iterations\n",
    "all_actions = defaultdict(int)\n",
    "for result in all_results.values():\n",
    "    for action, count in result['actions'].items():\n",
    "        all_actions[action] += count\n",
    "\n",
    "print('Overall action usage across all iterations:')\n",
    "for action in sorted(all_actions.keys()):\n",
    "    percentage = all_actions[action] / sum(all_actions.values()) * 100\n",
    "    print(f'  Action {action:2d}: {all_actions[action]:4d} times ({percentage:5.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Data Dictionary ===\\n')\n",
    "\n",
    "data_dict = {\n",
    "    'episode': 'Episode number',\n",
    "    'steps': 'Step within episode',\n",
    "    'X': 'X-coordinate position on track',\n",
    "    'Y': 'Y-coordinate position on track',\n",
    "    'yaw': 'Vehicle heading/orientation (radians)',\n",
    "    'steer': 'Steering angle (-30 to +30 degrees typically)',\n",
    "    'throttle': 'Speed/acceleration value',\n",
    "    'action': 'Discrete action taken (0-13)',\n",
    "    'reward': 'Reward received for this step',\n",
    "    'done': 'Whether episode is complete (boolean)',\n",
    "    'all_wheels_on_track': 'Track boundary detection (boolean)',\n",
    "    'progress': 'Percentage of track completed (0-100)',\n",
    "    'closest_waypoint': 'Nearest track waypoint ID',\n",
    "    'track_len': 'Total track length in meters',\n",
    "    'tstamp': 'Timestamp',\n",
    "    'episode_status': 'Episode status (prepare/in_progress/off_track/lap_complete)',\n",
    "    'pause_duration': 'Duration of any pauses'\n",
    "}\n",
    "\n",
    "for col, desc in data_dict.items():\n",
    "    print(f'{col:20s}: {desc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings and Recommendations\n",
    "\n",
    "### **Training Overview**\n",
    "This appears to be a reinforcement learning training log for an autonomous driving model, likely for **AWS DeepRacer** based on the data structure and variables.\n",
    "\n",
    "### **Key Findings:**\n",
    "\n",
    "#### **Training Progress**\n",
    "- **11 iterations** (0-10) with **220 total episodes** (20 episodes per iteration)\n",
    "- **18,175 total training steps** across all episodes\n",
    "- Track length: **17.71 meters** (relatively short track)\n",
    "\n",
    "#### **Performance Metrics**\n",
    "- **Overall success rate: 8.2%** (18 successful lap completions out of 220 episodes)\n",
    "- **Best iteration: #4** with 20% success rate (4/20 completions)\n",
    "- **202 off-track incidents** total\n",
    "- Average rewards remained relatively stable (0.904 to 0.931)\n",
    "\n",
    "#### **Action Space**\n",
    "- **14 discrete actions** (0-13) representing combinations of:\n",
    "  - Steering angles (left, straight, right)\n",
    "  - Throttle levels (different speeds)\n",
    "\n",
    "#### **Training Challenges**\n",
    "- **High failure rate**: Most episodes ended with the car going off-track\n",
    "- **Inconsistent performance**: Success rates varied significantly between iterations\n",
    "- **Late-stage regression**: Iterations 8 and 10 had 0% success rates\n",
    "- **Limited improvement**: Despite 220 episodes, overall performance didn't show strong upward trend\n",
    "\n",
    "#### **Successful Episodes**\n",
    "- Episodes 82, 83, 84, and 90 from iteration 4 completed full laps\n",
    "- Successful episodes averaged ~167 steps to complete the track\n",
    "- Position data shows cars starting around (4.97, 0.68) coordinates\n",
    "\n",
    "### **Recommendations**\n",
    "1. **Reward function tuning** may be needed to encourage track completion\n",
    "2. **Action space optimization** could help reduce off-track incidents\n",
    "3. **Hyperparameter adjustment** might improve learning stability\n",
    "4. **Extended training** with more episodes could be beneficial\n",
    "\n",
    "This training log represents a model still in early learning stages with significant room for improvement in track completion rates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
